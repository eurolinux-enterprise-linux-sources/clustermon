From: Jan Pokorny <jpokorny@redhat.com>
Date: Wed, 18 Nov 2011 19:26:01 +0200
Subject: [PATCH 5/6] fix bz742431: split+restructure poll handling in communicator

The old structure:
    1. server socket
        - POLLIN
        - POLLERR | POLLHUP | POLLNVAL
    2. client sockets
        ** POLLIN
        or POLLERR | POLLHUP | POLLNVAL
        or POLLOUT

The new structure:
    1. server socket -> handle_server_socket()
        - POLLIN (accept)
        - POLLERR | POLLHUP | POLLNVAL
    2. client sockets -> handle_client_socket()
        - POLLERR | POLLNVAL
        - POLLIN
        - POLLOUT
        - POLLHUP
        
Now it is worth to change "poll_data[i].events = POLLOUT"
to "poll_data[i].events |= POLLOUT" as these do not appear
as mutually exclusive now (one go can cover them both).

Also for client sockets -- POLLIN, add an optimization that
_delivery_point.msg_arrived() is called for the last received message
(if any) and not for all of them (see in-code comment).
The preprocessor conditional is kept for easy switch when needed.

Additionally, use "const" for method arguments when desirable and handle
previously suppressed exceptions.

Signed-off-by: Jan Pokorny <jpokorny@redhat.com>

diff -ur a/ricci/modules/cluster/clumon/src/daemon/Communicator.cpp b/ricci/modules/cluster/clumon/src/daemon/Communicator.cpp
--- a/ricci/modules/cluster/clumon/src/daemon/Communicator.cpp	2011-11-16 21:21:25.000000000 +0100
+++ b/ricci/modules/cluster/clumon/src/daemon/Communicator.cpp	2011-11-16 22:16:43.494341589 +0100
@@ -130,7 +130,11 @@
 						_peers.insert(pair<String, Peer>(name, Peer(name, _port)));
 						log("connected to " + name + ", socket "
 							+ _peers[name].get_sock_fd(), LogCommunicator);
-					} catch ( ... ) {}
+					} catch (String e) {
+						log("Communicator: connect to peers: " + e, LogCommunicator);
+					} catch ( ... ) {
+						log("Communicator: connect to peers: unknown error", LogCommunicator);
+					}
 				}
 			}
 		}
@@ -159,7 +163,7 @@
 }
 
 void
-Communicator::serve_sockets(vector<String>& names)
+Communicator::serve_sockets(const vector<String>& names)
 {
 	map<int, Peer> fd_peer;
 	for (map<String, Peer>::iterator
@@ -183,8 +187,9 @@
 	for (unsigned int i = 1 ; i < socks_num ; i++, iter++) {
 		poll_data[i].fd = iter->first;
 		poll_data[i].events = POLLIN;
+		// enable capturing also POLLOUT when there is something to send
 		if (!iter->second.outq_empty())
-			poll_data[i].events = POLLOUT;
+			poll_data[i].events |= POLLOUT;
 		poll_data[i].revents = 0;
 	}
 
#@@ -195,89 +200,115 @@
@@ -195,91 +200,115 @@
 	else if (ret == -1) {
 		if (errno == EINTR)
 			return;
-		else {
+		else
 			throw String("Communicator::run(): poll() error: ")
 					+ String(strerror(errno));
-		}
 	}
 
-	// process events
+	// handle events
 	for (unsigned int i = 0 ; i < socks_num && !shouldStop() ; i++) {
 		poll_fd& poll_info = poll_data[i];
 
-		// server socket
-		if (poll_info.fd == _serv_sock.get_sock()) {
-			if (poll_info.revents & POLLIN) {
-				try {
-					ClientSocket sock = _serv_sock.accept();
-					sock.nonblocking(true);
-					String hostname;
-
-					for (vector<String>::iterator
-							iter = names.begin() ;
-							iter != names.end() ;
-							iter++)
-					{
-						String& name = *iter;
-						if (sock.connected_to(name)) {
-							hostname = name;
-							break;
-						}
-					}
-
-					if (hostname.size()) {
-						_peers.insert(pair<String, Peer>(hostname, Peer(hostname, sock)));
-						log("accepted connection from " + hostname + ", socket "
-							+ sock.get_sock(), LogCommunicator);
-					}
-				} catch ( ... ) {}
-			}
-			if (poll_info.revents & (POLLERR | POLLHUP | POLLNVAL))
-				throw String("Communicator::run(): server socket error");
-		} else {
-			// client socket
-			Peer& peer = fd_peer[poll_info.fd];
-			if (poll_info.revents & POLLIN) {
-				vector<String> msgs;
-				try {
-					msgs = peer.receive();
-				} catch (String e) {
-					log("error receiving data from "
-							+ peer.hostname() + ": " + e,
-						LogCommunicator);
-					_peers.erase(peer.hostname());
-					continue;
-				} catch ( ... ) {
-					log("error receiving data from " + peer.hostname(),
-						LogCommunicator);
-					_peers.erase(peer.hostname());
-					continue;
-				}
+		if (i == 0)  /* alt.: poll_info.fd == _serv_sock.get_sock() */
+			handle_server_socket(names, poll_info.revents);
+		else
+			handle_client_socket(fd_peer[poll_info.fd], poll_info.revents);
+	}
+}
 
-				for (unsigned int i = 0 ; i < msgs.size() ; i++)
-					_delivery_point.msg_arrived(peer.hostname(), msgs[i]);
-				continue;
-			}
-			if (poll_info.revents & (POLLERR | POLLHUP | POLLNVAL)) {
-				_peers.erase(peer.hostname());
-				continue;
-			}
-			if (poll_info.revents & POLLOUT) {
-				try {
-					peer.send();
-				} catch (String e) {
-					log("error sending data to "
-							+ peer.hostname() + " : " + e,
-						LogCommunicator);
-					_peers.erase(peer.hostname());
-					continue;
-				} catch ( ... ) {
-					log("error sending data to " + peer.hostname(),
-						LogCommunicator);
-					_peers.erase(peer.hostname());
-					continue;
+inline void
+Communicator::handle_server_socket(const vector<String>& names, short revents)
+{
+	if (revents & POLLIN) {
+		try {
+			ClientSocket sock = _serv_sock.accept();
+			sock.nonblocking(true);
+			String hostname;
+
+			for (vector<String>::const_iterator
+					iter = names.begin() ;
+					iter != names.end() ;
+					iter++)
+			{
+				const String& name = *iter;
+				if (sock.connected_to(name)) {
+					hostname = name;
+					break;
 				}
 			}
+
+			if (hostname.size()) {
+				_peers.insert(pair<String, Peer>(hostname, Peer(hostname, sock)));
+				log("accepted connection from " + hostname + ", socket "
+					+ sock.get_sock(), LogCommunicator);
+			}
+		} catch (String e) {
+			log("error handling server socket :" + e,
+				LogCommunicator);
+		} catch ( ... ) {}
+	}
+	if (revents & (POLLERR | POLLHUP | POLLNVAL))
+		throw String("Communicator::run(): server socket error");
+}
+
+inline void
+Communicator::handle_client_socket(Peer& peer, short revents)
+{
+	if (revents & (POLLERR | POLLNVAL)) {
+		/* error condition on the socket */
+		_peers.erase(peer.hostname());
+		return;
+	}
+	if (revents & POLLIN) {
+		/* try to read all available */
+		vector<String> msgs;
+		try {
+			msgs = peer.receive();
+		} catch (String e) {
+			log("error receiving data from "
+					+ peer.hostname() + ": " + e,
+				LogCommunicator);
+			_peers.erase(peer.hostname());
+			return;
+		} catch ( ... ) {
+			log("error receiving data from " + peer.hostname(),
+				LogCommunicator);
+			_peers.erase(peer.hostname());
+			return;
+		}
+#define OPTIMIZE_MSG_ARRIVED 1
+#if OPTIMIZE_MSG_ARRIVED
+		// optimization: skip unnecessary refreshing of the monitor's
+		//               per-peer cache
+		// side-effect:  skipped XML cluster updates are not checked
+		//               for validity (does not change the things much)
+		if (msgs.size() > 0)
+			_delivery_point.msg_arrived(peer.hostname(), msgs.back());
+#else
+		for (unsigned int i = 0 ; i < msgs.size() ; i++)
+			_delivery_point.msg_arrived(peer.hostname(), msgs[i]);
+#endif
+	}
+	if (revents & POLLOUT) {
+		/* try to write a single piece (only) of XML update */
+		try {
+			peer.send();
+		} catch (String e) {
+			log("error sending data to "
+					+ peer.hostname() + " (" + this->_my_hostname + ") : " + e,
+				LogCommunicator);
+			_peers.erase(peer.hostname());
+		} catch ( ... ) {
+			log("error sending data to " + peer.hostname(),
+				LogCommunicator);
+			_peers.erase(peer.hostname());
 		}
 	}
+	if (revents & POLLHUP) {
+		/* handle remote peer closing the socket */
+		_peers.erase(peer.hostname());
+		return;
+	}
 }
 
 bool
diff -ur a/ricci/modules/cluster/clumon/src/daemon/Communicator.h b/ricci/modules/cluster/clumon/src/daemon/Communicator.h
--- a/ricci/modules/cluster/clumon/src/daemon/Communicator.h	2011-11-16 20:33:49.000000000 +0100
+++ b/ricci/modules/cluster/clumon/src/daemon/Communicator.h	2011-11-16 22:11:26.562443268 +0100
@@ -68,13 +68,16 @@
 		std::vector<String> _out_q;
 		std::vector<String> _peer_hostnames;
 
-		void serve_sockets(std::vector<String>&hostnames);
+		void serve_sockets(const std::vector<String>& names);
 		bool time_to_connect();
 		unsigned int _connect_time;
 		unsigned int _rand_state;
 
 		void run();
 
+		inline void handle_server_socket(const std::vector<String>& names, short revents);
+		inline void handle_client_socket(Peer& peer, short revents);
+
 		Communicator(const Communicator&);
 		Communicator& operator= (const Communicator&);
 };
